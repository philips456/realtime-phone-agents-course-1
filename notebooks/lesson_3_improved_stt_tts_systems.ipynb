{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95c953af-e10e-42b1-8520-e9635dd753b9",
   "metadata": {},
   "source": [
    "In this notebook, we'll walk you through the new Speech-to-Text (STT) and Text-to-Speech (TTS) models added to our project. To keep the architecture clean and maintainable, we've introduced two dedicated interfaces: STTModel for handling speech recognition and TTSModel for generating speech output. \n",
    "\n",
    "**Let's take a look at how each one works in practice!**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./img/streaming_handlers.png\" width=\"600\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60fc6d6-b8de-4397-91ee-6387b3126835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70ec513-2f7c-4f41-b3e9-4d2cc2ba5dde",
   "metadata": {},
   "source": [
    "## STT Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff19508-3795-467a-81d4-358d5126b91f",
   "metadata": {},
   "source": [
    "We added a helper function to fetch the STT model you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8019b3b4-a683-46c0-bd80-76ca0d440c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio\n",
    "\n",
    "from realtime_phone_agents.stt import get_stt_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b05363-fb5d-4908-a360-63e33d2eee8a",
   "metadata": {},
   "source": [
    "We are going to use these two example audios, to test the different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22446032-abae-484d-84b1-2c09c9ec2533",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(\"sounds/example.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202aad07-94f3-48ca-a08e-8b892fa3df78",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_example, samplerate = sf.read(\"sounds/example.mp3\", dtype=np.float32)   # decode MP3 â†’ numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124e962d-ba1c-4762-b9d4-5a93d13f9603",
   "metadata": {},
   "source": [
    "### Moonshine\n",
    "\n",
    "The one we've been using throughout the previous lessons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc57241-7452-483e-a6fa-1b7a0d877c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "moonshine = get_stt_model(\"moonshine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c19fed-3db5-4e98-b07f-b90ebf36ff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "moonshine.stt((samplerate, audio_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7319bc1d-e6e3-45bd-a2b4-c06a98da61c3",
   "metadata": {},
   "source": [
    "### Groq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe89be7-dbfa-4ae4-8aff-07d0cc05b21f",
   "metadata": {},
   "source": [
    "If you don't want to host the STT models yourself, you can use Groq for that purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf5a298-debd-4f26-b877-fecea99c8af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_groq = get_stt_model(\"whisper-groq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8c2443-3883-4317-97c5-4fc0bc0c940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_groq.stt((samplerate, audio_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a30f4f-43d8-4065-9af3-72a7fb9abfa9",
   "metadata": {},
   "source": [
    "### Faster-Whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6bcacc-f2f2-4f99-abe4-fa7e2a88e89b",
   "metadata": {},
   "source": [
    "Finally, let's host our own STT model using Runpod. In particular, we'll go with `faster-whisper`. **Make sure you have created the Runpod Pod, copy the URL and paste it in your `.env` file, under `FASTER_WHISPER__API_URL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaebba3-158b-402e-8f53-b7e988b78cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "faster_whisper = get_stt_model(\"faster-whisper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549a6c2b-5d90-4053-99ea-cf31a81a8121",
   "metadata": {},
   "outputs": [],
   "source": [
    "faster_whisper.stt((samplerate, audio_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08142eb9-00a5-4cb7-8654-5066c7ac3a69",
   "metadata": {},
   "source": [
    "## TTS Models\n",
    "\n",
    "Let's do the same for our TTS models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09b83df-7d9a-454c-bbc3-56fa328331df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "\n",
    "from realtime_phone_agents.tts import get_tts_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d59517b-e936-456f-b588-0a76f3f65527",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello, and welcome to The Neural Maze call center. Are you looking for a great apartment in Madrid?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c82bf17-2de7-4dae-8dd5-93f55fae2a54",
   "metadata": {},
   "source": [
    "### Kokoro\n",
    "\n",
    "The one we've been using throughout the previous lessons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed3970d-8e00-42f3-aa74-319ab45be1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "kokoro = get_tts_model(\"kokoro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6824d12-3199-4d7d-a342-684386f3a5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "samplerate, audio = kokoro.tts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86c534b-f2fe-4ed1-90af-c84d9a23c72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(audio, rate=samplerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bee60a-3b29-40c6-8b8d-488dfea779e8",
   "metadata": {},
   "source": [
    "### Orpheus 3B (Together.ai)\n",
    "\n",
    "As we did with Groq, you can rely on providers for the TTS models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c30d6c-8a81-46a9-89f6-acebe2db3d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "orpheus_togetherai = get_tts_model(\"together\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4ab0d8-4505-4c74-955b-3e9ecc1e9e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "samplerate, audio = orpheus_togetherai.tts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194d6245-e60d-4bd2-9e24-5c9ed6fadc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(audio, rate=samplerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9df46f-a35f-4ef1-9a68-fd7cbe4c7617",
   "metadata": {},
   "source": [
    "### Orpheus 3B (Runpod)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c7b1c8-57c9-4cb5-a626-f8839b07b22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "orpheus_runpod = get_tts_model(\"orpheus-runpod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e0d503-bc76-4a62-945a-d1650878a96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "samplerate, audio = await orpheus_runpod.tts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4115eb1-3579-46b5-8264-4d4694784506",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(audio, rate=samplerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3251b892-2a21-4e0e-b064-c4ca4d0e362e",
   "metadata": {},
   "source": [
    "The great thing about Orpheus is that it not only lets us switch between different voices, but also allows us to add emotional expressions to them.\n",
    "\n",
    "You can enhance the speech with the following emotive tags:\n",
    "`<laugh>`, `<chuckle>`, `<sigh>`, `<cough>`, `<sniffle>`, `<groan>`, `<yawn>`, `<gasp>`\n",
    "\n",
    "Available voices include: `tara`, `leah`, `jess`, `leo`, `dan`, `mia`, `zac`, `zoe`.\n",
    "\n",
    "Let's check some final examples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ee8ddd-97c7-4e2c-8d0d-c3530b61fd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "orpheus_runpod.set_voice(\"leo\")\n",
    "leo_message = \"Miguel told me I'm an AI Agent! <giggle> This guy is a liar\"\n",
    "samplerate, audio = await orpheus_runpod.tts(leo_message)\n",
    "Audio(audio, rate=samplerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c330d8d-5e00-471d-b24d-e06b78cf3f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "orpheus_runpod.set_voice(\"tara\")\n",
    "zoe_message = \"I'm so tired of working at this call center <yawn> Just need some sleep\"\n",
    "samplerate, audio = await orpheus_runpod.tts(zoe_message)\n",
    "Audio(audio, rate=samplerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3c3a32-736f-4e1c-8c7e-d7b2da645dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "samplerate, audio = await orpheus_runpod.tts(long_message)\n",
    "Audio(audio, rate=samplerate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
